{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "import h5py as hdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import glob \n",
    "import seaborn as sns\n",
    "#import netCDF as cdf \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following dataframes were generated based on retrievals performed with Erik's Refset (943-1013 hpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_1000  = 'SIFTER2/Level2_noise/Level2_1000hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_800   = 'SIFTER2/Level2_noise/Level2_800hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_700   = 'SIFTER2/Level2_noise/Level2_700hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_600   = 'SIFTER2/Level2_noise/Level2_600hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_400   = 'SIFTER2/Level2_noise/Level2_400hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_all   = 'SIFTER2/Level2_noise/Level2_Allhpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "\n",
    "files = [f_1000,f_800,f_700,f_600,f_400,f_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFTER2/Level2_noise/Level2_1000hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n",
      "SIFTER2/Level2_noise/Level2_800hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n",
      "SIFTER2/Level2_noise/Level2_700hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n",
      "SIFTER2/Level2_noise/Level2_600hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n",
      "SIFTER2/Level2_noise/Level2_400hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n",
      "SIFTER2/Level2_noise/Level2_Allhpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print f\n",
    "    data        = hdf.File(f,'r') \n",
    "    group       = data['level2']\n",
    "    isFile   = isinstance(group,hdf.File)\n",
    "    isGroup  = isinstance(group,hdf.Group)\n",
    "    isDataset= isinstance(group,hdf.Dataset)\n",
    "    print (isFile,isGroup,isDataset)\n",
    "    list_items_in_group = group.items()\n",
    "    #for i in list_items_in_group:\n",
    "    #    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'SIFTER2/Level2_noise/Level2_1000hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_1000hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(1, 'SIFTER2/Level2_noise/Level2_800hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_800hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(2, 'SIFTER2/Level2_noise/Level2_700hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_700hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(3, 'SIFTER2/Level2_noise/Level2_600hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_600hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(4, 'SIFTER2/Level2_noise/Level2_400hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_400hpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(5, 'SIFTER2/Level2_noise/Level2_Allhpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_Allhpa_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n"
     ]
    }
   ],
   "source": [
    "# Retrievals with Erik Dataset.\n",
    "columns       = ['Fs','height','Autocorr','chi2']\n",
    "d             = np.array(np.ones((1000,len(columns))))\n",
    "\n",
    "dataF_400     = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_600     = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_700     = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_800     = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_1000    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_all     = pd.DataFrame(data=d,columns=columns)\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    print (i,f)\n",
    "        \n",
    "    data      = hdf.File(f,'r') \n",
    "    autocorr  = np.array(data['level2/autocorrelation'])\n",
    "    refl_err  = np.array(data['level2/refl_err'])\n",
    "    residuals = np.array(data['level2/res'])\n",
    "    wav       = np.array(data['level2/wavelength'])\n",
    "    chi2      = np.array(data['level2/chi2_red'])\n",
    "    height    = np.array(data['level2/height'])\n",
    "    Fs        = np.array(data['level2/param'])\n",
    "    Fs        = np.array([item[0] for item in Fs])\n",
    "    cov       = np.array(data['level2/param_cov'])\n",
    "\n",
    "    #print (residuals.shape)\n",
    "    \n",
    "    if i == 0:\n",
    "        print (f)\n",
    "        dataF_1000['Autocorr']       = autocorr\n",
    "        dataF_1000['Fs']             = Fs\n",
    "        dataF_1000['height']         = height[0]\n",
    "        dataF_1000['chi2']           = chi2\n",
    "        res1000                      = residuals\n",
    "        dataF_1000.to_pickle('dataframes/df_1000')\n",
    "        np.save('dataframes/res1000', res1000)\n",
    "\n",
    "    if i == 1:\n",
    "        print (f)\n",
    "        dataF_800['Autocorr']       = autocorr\n",
    "        dataF_800['Fs']             = Fs\n",
    "        dataF_800['height']         = height[0]\n",
    "        dataF_800['chi2']           = chi2\n",
    "        res800                      = residuals\n",
    "        dataF_800.to_pickle('dataframes/df_800')\n",
    "        np.save('dataframes/res800', res800)\n",
    "    \n",
    "    if i == 2:\n",
    "        print (f)\n",
    "        dataF_700['Autocorr']       = autocorr\n",
    "        dataF_700['Fs']             = Fs\n",
    "        dataF_700['height']         = height[0]\n",
    "        dataF_700['chi2']           = chi2\n",
    "        res700                      = residuals\n",
    "        dataF_700.to_pickle('dataframes/df_700')\n",
    "        np.save('dataframes/res700', res700)\n",
    "    \n",
    "    if i == 3:\n",
    "        print (f)\n",
    "        dataF_600['Autocorr']       = autocorr\n",
    "        dataF_600['Fs']             = Fs\n",
    "        dataF_600['height']         = height[0]\n",
    "        dataF_600['chi2']           = chi2\n",
    "        res600                      = residuals\n",
    "        dataF_600.to_pickle('dataframes/df_600')\n",
    "        np.save('dataframes/res600', res600)\n",
    "        \n",
    "    if i == 4:\n",
    "        print (f)\n",
    "        dataF_400['Autocorr']       = autocorr\n",
    "        dataF_400['Fs']             = Fs\n",
    "        dataF_400['height']         = height[0]\n",
    "        dataF_400['chi2']           = chi2\n",
    "        res400                      = residuals \n",
    "        dataF_400.to_pickle('dataframes/df_400')\n",
    "        np.save('dataframes/res400', res400)\n",
    "        \n",
    "    if i == 5:\n",
    "        print (f)\n",
    "        dataF_all['Autocorr']       = autocorr\n",
    "        dataF_all['Fs']             = Fs\n",
    "        dataF_all['height']         = height[0]\n",
    "        dataF_all['chi2']           = chi2\n",
    "        resAll                      = residuals\n",
    "        dataF_all.to_pickle('dataframes/df_all')\n",
    "        np.save('dataframes/resAll', resAll)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following dataframes are based on retrievals performed using the All hpa refset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_400_refAll = 'SIFTER2/Level2_noise/Level2_400hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_600_refAll = 'SIFTER2/Level2_noise/Level2_600hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_700_refAll = 'SIFTER2/Level2_noise/Level2_700hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_800_refAll = 'SIFTER2/Level2_noise/Level2_800hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_1000_refAll= 'SIFTER2/Level2_noise/Level2_1000hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_all_refAll = 'SIFTER2/Level2_noise/Level2_all_hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "\n",
    "files = [f_400_refAll,f_600_refAll,f_700_refAll,f_800_refAll,f_1000_refAll,f_all_refAll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'SIFTER2/Level2_noise/Level2_400hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_400hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(1, 'SIFTER2/Level2_noise/Level2_600hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_600hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(2, 'SIFTER2/Level2_noise/Level2_700hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_700hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(3, 'SIFTER2/Level2_noise/Level2_800hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_800hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(4, 'SIFTER2/Level2_noise/Level2_1000hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_1000hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(5, 'SIFTER2/Level2_noise/Level2_all_hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_all_hpa_allrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n"
     ]
    }
   ],
   "source": [
    "columns                = ['Fs','height','Autocorr','chi2']\n",
    "d                      = np.array(np.ones((1000,len(columns))))\n",
    "\n",
    "dataF_400_allrefset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_600_allrefset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_700_allrefset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_800_allrefset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_1000_allrefset   = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_allhpa_allrefset = pd.DataFrame(data=d,columns=columns)\n",
    "\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    print (i,f)\n",
    "        \n",
    "    data      = hdf.File(f,'r') \n",
    "    autocorr  = np.array(data['level2/autocorrelation'])\n",
    "    refl_err  = np.array(data['level2/refl_err'])\n",
    "    residuals = np.array(data['level2/res'])\n",
    "    wav       = np.array(data['level2/wavelength'])\n",
    "    chi2      = np.array(data['level2/chi2_red'])\n",
    "    height    = np.array(data['level2/height'])\n",
    "    Fs        = np.array(data['level2/param'])\n",
    "    Fs        = np.array([item[0] for item in Fs])\n",
    "    cov       = np.array(data['level2/param_cov'])\n",
    "\n",
    "    #print (residuals.shape)\n",
    "        \n",
    "    if i == 0:\n",
    "        print (f)\n",
    "        dataF_400_allrefset['Autocorr']       = autocorr\n",
    "        dataF_400_allrefset['Fs']             = Fs\n",
    "        dataF_400_allrefset['height']         = height[0]\n",
    "        dataF_400_allrefset['chi2']           = chi2\n",
    "        res400_allrefset                      = residuals \n",
    "        np.save('Residuals/res400_allrefset', res400_allrefset)\n",
    "        dataF_400_allrefset.to_pickle('dataframes/df_400_allrefset')\n",
    "        \n",
    "    if i == 1:\n",
    "        print (f)\n",
    "        dataF_600_allrefset['Autocorr']       = autocorr\n",
    "        dataF_600_allrefset['Fs']             = Fs\n",
    "        dataF_600_allrefset['height']         = height[0]\n",
    "        dataF_600_allrefset['chi2']           = chi2\n",
    "        res600_allrefset                      = residuals \n",
    "        np.save('Residuals/res600_allrefset', res600_allrefset)\n",
    "        dataF_600_allrefset.to_pickle('dataframes/df_600_allrefset')\n",
    "        \n",
    "    if i == 2:\n",
    "        print (f)\n",
    "        dataF_700_allrefset['Autocorr']       = autocorr\n",
    "        dataF_700_allrefset['Fs']             = Fs\n",
    "        dataF_700_allrefset['height']         = height[0]\n",
    "        dataF_700_allrefset['chi2']           = chi2\n",
    "        res700_allrefset                      = residuals \n",
    "        np.save('Residuals/res700_allrefset', res700_allrefset)\n",
    "        dataF_700_allrefset.to_pickle('dataframes/df_700_allrefset')\n",
    "        \n",
    "    if i == 3:\n",
    "        print (f)\n",
    "        dataF_800_allrefset['Autocorr']       = autocorr\n",
    "        dataF_800_allrefset['Fs']             = Fs\n",
    "        dataF_800_allrefset['height']         = height[0]\n",
    "        dataF_800_allrefset['chi2']           = chi2\n",
    "        res800_allrefset                      = residuals \n",
    "        np.save('Residuals/res800_allrefset', res800_allrefset)\n",
    "        dataF_800_allrefset.to_pickle('dataframes/df_800_allrefset')\n",
    "    \n",
    "    if i == 4:\n",
    "        print (f)\n",
    "        dataF_1000_allrefset['Autocorr']       = autocorr\n",
    "        dataF_1000_allrefset['Fs']             = Fs\n",
    "        dataF_1000_allrefset['height']         = height[0]\n",
    "        dataF_1000_allrefset['chi2']           = chi2\n",
    "        res1000_allrefset                      = residuals\n",
    "        np.save('Residuals/res1000_allrefset', res1000_allrefset)\n",
    "        dataF_1000_allrefset.to_pickle('dataframes/df_1000_allrefset')\n",
    "    \n",
    "    if i == 5:\n",
    "        print (f)\n",
    "        dataF_allhpa_allrefset['Autocorr']       = autocorr\n",
    "        dataF_allhpa_allrefset['Fs']             = Fs\n",
    "        dataF_allhpa_allrefset['height']         = height[0]\n",
    "        dataF_allhpa_allrefset['chi2']           = chi2\n",
    "        resallhpa_allrefset                      = residuals \n",
    "        np.save('Residuals/resAllhpa_allrefset', resallhpa_allrefset)\n",
    "        dataF_allhpa_allrefset.to_pickle('dataframes/df_allhpa_allrefset')\n",
    "        \n",
    "        #falta meter 1000hpa como level1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following dataframes are based on retrievals performed using the 400 hpa refset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_400_ref400 = 'SIFTER2/Level2_noise/Level2_400hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_600_ref400 = 'SIFTER2/Level2_noise/Level2_600hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_700_ref400 = 'SIFTER2/Level2_noise/Level2_700hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_800_ref400 = 'SIFTER2/Level2_noise/Level2_800hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_1000_ref400= 'SIFTER2/Level2_noise/Level2_1000hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_all_ref400 = 'SIFTER2/Level2_noise/Level2_all_hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [f_400_ref400,f_600_ref400,f_700_ref400,f_800_ref400,f_1000_ref400,f_all_ref400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'SIFTER2/Level2_noise/Level2_400hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_400hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(1, 'SIFTER2/Level2_noise/Level2_600hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_600hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(2, 'SIFTER2/Level2_noise/Level2_700hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_700hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(3, 'SIFTER2/Level2_noise/Level2_800hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_800hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(4, 'SIFTER2/Level2_noise/Level2_1000hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_1000hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(5, 'SIFTER2/Level2_noise/Level2_all_hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_all_hpa_400refset/2009/01/SIFTER2_M02_L2_2009_01_01\n"
     ]
    }
   ],
   "source": [
    "columns                = ['Fs','height','Autocorr','chi2']\n",
    "d                      = np.array(np.ones((1000,len(columns))))\n",
    "\n",
    "dataF_400_400refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_600_400refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_700_400refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_800_400refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_1000_400refset   = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_allhpa_400refset = pd.DataFrame(data=d,columns=columns)\n",
    "\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    print (i,f)\n",
    "        \n",
    "    data      = hdf.File(f,'r') \n",
    "    autocorr  = np.array(data['level2/autocorrelation'])\n",
    "    refl_err  = np.array(data['level2/refl_err'])\n",
    "    residuals = np.array(data['level2/res'])\n",
    "    wav       = np.array(data['level2/wavelength'])\n",
    "    chi2      = np.array(data['level2/chi2_red'])\n",
    "    height    = np.array(data['level2/height'])\n",
    "    Fs        = np.array(data['level2/param'])\n",
    "    Fs        = np.array([item[0] for item in Fs])\n",
    "    cov       = np.array(data['level2/param_cov'])\n",
    "        \n",
    "    if i == 0:\n",
    "        print (f)\n",
    "        dataF_400_400refset['Autocorr']       = autocorr\n",
    "        dataF_400_400refset['Fs']             = Fs\n",
    "        dataF_400_400refset['height']         = height[0]\n",
    "        dataF_400_400refset['chi2']           = chi2\n",
    "        res400_400refset                      = residuals \n",
    "        np.save('Residuals/res400_400refset', res400_400refset)\n",
    "        dataF_400_400refset.to_pickle('dataframes/df_400_400refset')\n",
    "           \n",
    "    if i == 1:\n",
    "        print (f)\n",
    "        dataF_600_400refset['Autocorr']       = autocorr\n",
    "        dataF_600_400refset['Fs']             = Fs\n",
    "        dataF_600_400refset['height']         = height[0]\n",
    "        dataF_600_400refset['chi2']           = chi2\n",
    "        res600_400refset                      = residuals \n",
    "        np.save('Residuals/res600_400refset', res600_400refset)\n",
    "        dataF_600_400refset.to_pickle('dataframes/df_600_400refset')\n",
    "        \n",
    "    if i == 2:\n",
    "        print (f)\n",
    "        dataF_700_400refset['Autocorr']       = autocorr\n",
    "        dataF_700_400refset['Fs']             = Fs\n",
    "        dataF_700_400refset['height']         = height[0]\n",
    "        dataF_700_400refset['chi2']           = chi2\n",
    "        res700_400refset                      = residuals \n",
    "        np.save('Residuals/res700_400refset', res700_400refset)\n",
    "        dataF_700_400refset.to_pickle('dataframes/df_700_400refset')\n",
    "    \n",
    "    if i == 3:\n",
    "        print (f)\n",
    "        dataF_800_400refset['Autocorr']       = autocorr\n",
    "        dataF_800_400refset['Fs']             = Fs\n",
    "        dataF_800_400refset['height']         = height[0]\n",
    "        dataF_800_400refset['chi2']           = chi2\n",
    "        res800_400refset                      = residuals \n",
    "        np.save('Residuals/res800_400refset', res800_400refset)\n",
    "        dataF_800_400refset.to_pickle('dataframes/df_800_400refset')\n",
    "    \n",
    "    if i == 4:\n",
    "        print (f)\n",
    "        dataF_1000_400refset['Autocorr']       = autocorr\n",
    "        dataF_1000_400refset['Fs']             = Fs\n",
    "        dataF_1000_400refset['height']         = height[0]\n",
    "        dataF_1000_400refset['chi2']           = chi2\n",
    "        res1000_400refset                      = residuals \n",
    "        np.save('Residuals/res1000_400refset', res1000_400refset)\n",
    "        dataF_1000_400refset.to_pickle('dataframes/df_1000_400refset')\n",
    "    \n",
    "    if i == 5:\n",
    "        print (f)\n",
    "        dataF_allhpa_400refset['Autocorr']       = autocorr\n",
    "        dataF_allhpa_400refset['Fs']             = Fs\n",
    "        dataF_allhpa_400refset['height']         = height[0]\n",
    "        dataF_allhpa_400refset['chi2']           = chi2\n",
    "        resallhpa_400refset                      = residuals \n",
    "        np.save('Residuals/resAllhpa_400refset', resallhpa_400refset)\n",
    "        dataF_allhpa_400refset.to_pickle('dataframes/df_allhpa_400refset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following dataframes are based on retrievals performed using the 600 hpa refset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_400_ref600 = 'SIFTER2/Level2_noise/Level2_400hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_600_ref600 = 'SIFTER2/Level2_noise/Level2_600hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_700_ref600 = 'SIFTER2/Level2_noise/Level2_700hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_800_ref600 = 'SIFTER2/Level2_noise/Level2_800hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_1000_ref600= 'SIFTER2/Level2_noise/Level2_1000hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_all_ref600 = 'SIFTER2/Level2_noise/Level2_all_hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [f_400_ref600,f_600_ref600,f_700_ref600,f_800_ref600,f_1000_ref600,f_all_ref600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'SIFTER2/Level2_noise/Level2_400hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_400hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(1, 'SIFTER2/Level2_noise/Level2_600hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_600hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(2, 'SIFTER2/Level2_noise/Level2_700hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_700hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(3, 'SIFTER2/Level2_noise/Level2_800hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_800hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(4, 'SIFTER2/Level2_noise/Level2_1000hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_1000hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(5, 'SIFTER2/Level2_noise/Level2_all_hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_all_hpa_600refset/2009/01/SIFTER2_M02_L2_2009_01_01\n"
     ]
    }
   ],
   "source": [
    "columns                = ['Fs','height','Autocorr','chi2']\n",
    "d                      = np.array(np.ones((1000,len(columns))))\n",
    "\n",
    "dataF_400_600refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_600_600refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_700_600refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_800_600refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_1000_600refset   = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_allhpa_600refset = pd.DataFrame(data=d,columns=columns)\n",
    "\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    print (i,f)\n",
    "        \n",
    "    data      = hdf.File(f,'r') \n",
    "    autocorr  = np.array(data['level2/autocorrelation'])\n",
    "    refl_err  = np.array(data['level2/refl_err'])\n",
    "    residuals = np.array(data['level2/res'])\n",
    "    wav       = np.array(data['level2/wavelength'])\n",
    "    chi2      = np.array(data['level2/chi2_red'])\n",
    "    height    = np.array(data['level2/height'])\n",
    "    Fs        = np.array(data['level2/param'])\n",
    "    Fs        = np.array([item[0] for item in Fs])\n",
    "    cov       = np.array(data['level2/param_cov'])\n",
    "        \n",
    "    if i == 0:\n",
    "        print (f)\n",
    "        dataF_400_600refset['Autocorr']       = autocorr\n",
    "        dataF_400_600refset['Fs']             = Fs\n",
    "        dataF_400_600refset['height']         = height[0]\n",
    "        dataF_400_600refset['chi2']           = chi2\n",
    "        res400_600refset                      = residuals \n",
    "        np.save('Residuals/res400_600refset', res400_600refset)\n",
    "        dataF_400_600refset.to_pickle('dataframes/df_400_600refset')\n",
    "           \n",
    "    if i == 1:\n",
    "        print (f)\n",
    "        dataF_600_600refset['Autocorr']       = autocorr\n",
    "        dataF_600_600refset['Fs']             = Fs\n",
    "        dataF_600_600refset['height']         = height[0]\n",
    "        dataF_600_600refset['chi2']           = chi2\n",
    "        res600_600refset                      = residuals \n",
    "        np.save('Residuals/res600_600refset', res600_600refset)\n",
    "        dataF_600_600refset.to_pickle('dataframes/df_600_600refset')\n",
    "        \n",
    "    if i == 2:\n",
    "        print (f)\n",
    "        dataF_700_600refset['Autocorr']       = autocorr\n",
    "        dataF_700_600refset['Fs']             = Fs\n",
    "        dataF_700_600refset['height']         = height[0]\n",
    "        dataF_700_600refset['chi2']           = chi2\n",
    "        res700_600refset                      = residuals \n",
    "        np.save('Residuals/res700_600refset', res700_600refset)\n",
    "        dataF_700_600refset.to_pickle('dataframes/df_700_600refset')\n",
    "        \n",
    "    if i == 3:\n",
    "        print (f)\n",
    "        dataF_800_600refset['Autocorr']       = autocorr\n",
    "        dataF_800_600refset['Fs']             = Fs\n",
    "        dataF_800_600refset['height']         = height[0]\n",
    "        dataF_800_600refset['chi2']           = chi2\n",
    "        res800_600refset                      = residuals \n",
    "        np.save('Residuals/res800_600refset', res800_600refset)\n",
    "        dataF_800_600refset.to_pickle('dataframes/df_800_600refset')\n",
    "    \n",
    "    if i == 4:\n",
    "        print (f)\n",
    "        dataF_1000_600refset['Autocorr']       = autocorr\n",
    "        dataF_1000_600refset['Fs']             = Fs\n",
    "        dataF_1000_600refset['height']         = height[0]\n",
    "        dataF_1000_600refset['chi2']           = chi2\n",
    "        res1000_600refset                      = residuals \n",
    "        np.save('Residuals/res1000_600refset', res1000_600refset)\n",
    "        dataF_1000_600refset.to_pickle('dataframes/df_1000_600refset')\n",
    "    \n",
    "    if i == 5:\n",
    "        print (f)\n",
    "        dataF_allhpa_600refset['Autocorr']       = autocorr\n",
    "        dataF_allhpa_600refset['Fs']             = Fs\n",
    "        dataF_allhpa_600refset['height']         = height[0]\n",
    "        dataF_allhpa_600refset['chi2']           = chi2\n",
    "        resallhpa_600refset                      = residuals \n",
    "        np.save('Residuals/resAllhpa_600refset', resallhpa_600refset)\n",
    "        dataF_allhpa_600refset.to_pickle('dataframes/df_allhpa_600refset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following dataframes are based on retrievals performed using the 700 hpa refset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_400_ref700 = 'SIFTER2/Level2_noise/Level2_400hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_600_ref700 = 'SIFTER2/Level2_noise/Level2_600hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_700_ref700 = 'SIFTER2/Level2_noise/Level2_700hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_800_ref700 = 'SIFTER2/Level2_noise/Level2_800hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_1000_ref700= 'SIFTER2/Level2_noise/Level2_1000hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_all_ref700 = 'SIFTER2/Level2_noise/Level2_all_hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = [f_400_ref700,f_600_ref700,f_700_ref700,f_800_ref700,f_1000_ref700,f_all_ref700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'SIFTER2/Level2_noise/Level2_400hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_400hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(1, 'SIFTER2/Level2_noise/Level2_600hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_600hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(2, 'SIFTER2/Level2_noise/Level2_700hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_700hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(3, 'SIFTER2/Level2_noise/Level2_800hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_800hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(4, 'SIFTER2/Level2_noise/Level2_1000hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_1000hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(5, 'SIFTER2/Level2_noise/Level2_all_hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_all_hpa_700refset/2009/01/SIFTER2_M02_L2_2009_01_01\n"
     ]
    }
   ],
   "source": [
    "columns                = ['Fs','height','Autocorr','chi2']\n",
    "d                      = np.array(np.ones((1000,len(columns))))\n",
    "\n",
    "dataF_400_700refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_600_700refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_700_700refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_800_700refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_1000_700refset   = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_allhpa_700refset = pd.DataFrame(data=d,columns=columns)\n",
    "\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    print (i,f)\n",
    "        \n",
    "    data      = hdf.File(f,'r') \n",
    "    autocorr  = np.array(data['level2/autocorrelation'])\n",
    "    refl_err  = np.array(data['level2/refl_err'])\n",
    "    residuals = np.array(data['level2/res'])\n",
    "    wav       = np.array(data['level2/wavelength'])\n",
    "    chi2      = np.array(data['level2/chi2_red'])\n",
    "    height    = np.array(data['level2/height'])\n",
    "    Fs        = np.array(data['level2/param'])\n",
    "    Fs        = np.array([item[0] for item in Fs])\n",
    "    cov       = np.array(data['level2/param_cov'])\n",
    "        \n",
    "    if i == 0:\n",
    "        print (f)\n",
    "        dataF_400_700refset['Autocorr']       = autocorr\n",
    "        dataF_400_700refset['Fs']             = Fs\n",
    "        dataF_400_700refset['height']         = height[0]\n",
    "        dataF_400_700refset['chi2']           = chi2\n",
    "        res400_700refset                      = residuals \n",
    "        np.save('Residuals/res400_700refset', res400_700refset)\n",
    "        dataF_400_700refset.to_pickle('dataframes/df_400_700refset')\n",
    "           \n",
    "    if i == 1:\n",
    "        print (f)\n",
    "        dataF_600_700refset['Autocorr']       = autocorr\n",
    "        dataF_600_700refset['Fs']             = Fs\n",
    "        dataF_600_700refset['height']         = height[0]\n",
    "        dataF_600_700refset['chi2']           = chi2\n",
    "        res600_700refset                      = residuals \n",
    "        np.save('Residuals/res600_700refset', res600_700refset)\n",
    "        dataF_600_700refset.to_pickle('dataframes/df_600_700refset')\n",
    "        \n",
    "    if i == 2:\n",
    "        print (f)\n",
    "        dataF_700_700refset['Autocorr']       = autocorr\n",
    "        dataF_700_700refset['Fs']             = Fs\n",
    "        dataF_700_700refset['height']         = height[0]\n",
    "        dataF_700_700refset['chi2']           = chi2\n",
    "        res700_700refset                      = residuals \n",
    "        np.save('Residuals/res700_700refset', res700_700refset)\n",
    "        dataF_700_700refset.to_pickle('dataframes/df_700_700refset')\n",
    "        \n",
    "    if i == 3:\n",
    "        print (f)\n",
    "        dataF_800_700refset['Autocorr']       = autocorr\n",
    "        dataF_800_700refset['Fs']             = Fs\n",
    "        dataF_800_700refset['height']         = height[0]\n",
    "        dataF_800_700refset['chi2']           = chi2\n",
    "        res800_700refset                      = residuals \n",
    "        np.save('Residuals/res800_700refset', res800_700refset)\n",
    "        dataF_800_700refset.to_pickle('dataframes/df_800_700refset')\n",
    "    \n",
    "    if i == 4:\n",
    "        print (f)\n",
    "        dataF_1000_700refset['Autocorr']       = autocorr\n",
    "        dataF_1000_700refset['Fs']             = Fs\n",
    "        dataF_1000_700refset['height']         = height[0]\n",
    "        dataF_1000_700refset['chi2']           = chi2\n",
    "        res1000_700refset                      = residuals \n",
    "        np.save('Residuals/res1000_700refset', res1000_700refset)\n",
    "        dataF_1000_700refset.to_pickle('dataframes/df_1000_700refset')\n",
    "    \n",
    "    if i == 5:\n",
    "        print (f)\n",
    "        dataF_allhpa_700refset['Autocorr']       = autocorr\n",
    "        dataF_allhpa_700refset['Fs']             = Fs\n",
    "        dataF_allhpa_700refset['height']         = height[0]\n",
    "        dataF_allhpa_700refset['chi2']           = chi2\n",
    "        resallhpa_700refset                      = residuals \n",
    "        np.save('Residuals/resAllhpa_700refset', resallhpa_700refset)\n",
    "        dataF_allhpa_700refset.to_pickle('dataframes/df_allhpa_700refset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The following dataframes are based on retrievals performed using the 800 hpa refset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_400_ref800 = 'SIFTER2/Level2_noise/Level2_400hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_600_ref800 = 'SIFTER2/Level2_noise/Level2_600hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_700_ref800 = 'SIFTER2/Level2_noise/Level2_700hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_800_ref800 = 'SIFTER2/Level2_noise/Level2_800hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_1000_ref800= 'SIFTER2/Level2_noise/Level2_1000hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_all_ref800 = 'SIFTER2/Level2_noise/Level2_all_hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = [f_400_ref800,f_600_ref800,f_700_ref800,f_800_ref800,f_1000_ref800,f_all_ref800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'SIFTER2/Level2_noise/Level2_400hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_400hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(1, 'SIFTER2/Level2_noise/Level2_600hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_600hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(2, 'SIFTER2/Level2_noise/Level2_700hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_700hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(3, 'SIFTER2/Level2_noise/Level2_800hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_800hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(4, 'SIFTER2/Level2_noise/Level2_1000hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_1000hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(5, 'SIFTER2/Level2_noise/Level2_all_hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level2_noise/Level2_all_hpa_800refset/2009/01/SIFTER2_M02_L2_2009_01_01\n"
     ]
    }
   ],
   "source": [
    "columns                = ['Fs','height','Autocorr','chi2']\n",
    "d                      = np.array(np.ones((1000,len(columns))))\n",
    "\n",
    "dataF_400_800refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_600_800refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_700_800refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_800_800refset    = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_1000_800refset   = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_allhpa_800refset = pd.DataFrame(data=d,columns=columns)\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    print (i,f)\n",
    "        \n",
    "    data      = hdf.File(f,'r') \n",
    "    autocorr  = np.array(data['level2/autocorrelation'])\n",
    "    refl_err  = np.array(data['level2/refl_err'])\n",
    "    residuals = np.array(data['level2/res'])\n",
    "    wav       = np.array(data['level2/wavelength'])\n",
    "    chi2      = np.array(data['level2/chi2_red'])\n",
    "    height    = np.array(data['level2/height'])\n",
    "    Fs        = np.array(data['level2/param'])\n",
    "    Fs        = np.array([item[0] for item in Fs])\n",
    "    cov       = np.array(data['level2/param_cov'])\n",
    "        \n",
    "    if i == 0:\n",
    "        print (f)\n",
    "        dataF_400_800refset['Autocorr']       = autocorr\n",
    "        dataF_400_800refset['Fs']             = Fs\n",
    "        dataF_400_800refset['height']         = height[0]\n",
    "        dataF_400_800refset['chi2']           = chi2\n",
    "        res400_800refset                      = residuals \n",
    "        np.save('Residuals/res400_800refset', res400_800refset)\n",
    "        dataF_400_800refset.to_pickle('dataframes/df_400_800refset')\n",
    "           \n",
    "    if i == 1:\n",
    "        print (f)\n",
    "        dataF_600_800refset['Autocorr']       = autocorr\n",
    "        dataF_600_800refset['Fs']             = Fs\n",
    "        dataF_600_800refset['height']         = height[0]\n",
    "        dataF_600_800refset['chi2']           = chi2\n",
    "        res600_800refset                      = residuals \n",
    "        np.save('Residuals/res600_800refset', res600_800refset)\n",
    "        dataF_600_800refset.to_pickle('dataframes/df_600_800refset')\n",
    "        \n",
    "    if i == 2:\n",
    "        print (f)\n",
    "        dataF_700_800refset['Autocorr']       = autocorr\n",
    "        dataF_700_800refset['Fs']             = Fs\n",
    "        dataF_700_800refset['height']         = height[0]\n",
    "        dataF_700_800refset['chi2']           = chi2\n",
    "        res700_800refset                      = residuals \n",
    "        np.save('Residuals/res700_800refset', res700_800refset)\n",
    "        dataF_700_800refset.to_pickle('dataframes/df_700_800refset')\n",
    "        \n",
    "    if i == 3:\n",
    "        print (f)\n",
    "        dataF_800_800refset['Autocorr']       = autocorr\n",
    "        dataF_800_800refset['Fs']             = Fs\n",
    "        dataF_800_800refset['height']         = height[0]\n",
    "        dataF_800_800refset['chi2']           = chi2\n",
    "        res800_800refset                      = residuals \n",
    "        np.save('Residuals/res800_800refset', res800_800refset)\n",
    "        dataF_800_800refset.to_pickle('dataframes/df_800_800refset')\n",
    "    \n",
    "    if i == 4:\n",
    "        print (f)\n",
    "        dataF_1000_800refset['Autocorr']       = autocorr\n",
    "        dataF_1000_800refset['Fs']             = Fs\n",
    "        dataF_1000_800refset['height']         = height[0]\n",
    "        dataF_1000_800refset['chi2']           = chi2\n",
    "        res1000_800refset                      = residuals \n",
    "        np.save('Residuals/res1000_800refset', res1000_800refset)\n",
    "        dataF_1000_800refset.to_pickle('dataframes/df_1000_800refset')\n",
    "    \n",
    "    if i == 5:\n",
    "        print (f)\n",
    "        dataF_allhpa_800refset['Autocorr']       = autocorr\n",
    "        dataF_allhpa_800refset['Fs']             = Fs\n",
    "        dataF_allhpa_800refset['height']         = height[0]\n",
    "        dataF_allhpa_800refset['chi2']           = chi2\n",
    "        resallhpa_800refset                      = residuals\n",
    "        np.save('Residuals/resAllhpa_800refset', resallhpa_800refset)\n",
    "        dataF_allhpa_800refset.to_pickle('dataframes/df_allhpa_800refset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following dataframes are based on retrievals performed using the allhpa on real GOME2a observations for 2011-01 and 2009-01-01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_GOME2_2011   = 'SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2011_allhpa_refset/2011/01/SIFTER2_M02_L2_2011_01_01'\n",
    "f_GOME2_2009   = 'SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "f_GOME2_2009_2 = 'SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_allhpa_refset/2009/01/SIFTER2_M02_L2_2009_01_01'\n",
    "files          = [f_GOME2_2011,f_GOME2_2009,f_GOME2_2009_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2011_allhpa_refset/2011/01/SIFTER2_M02_L2_2011_01_01\n",
      "(False, True, False)\n",
      "(u'CloudFraction', <HDF5 dataset \"CloudFraction\": shape (58634, 1), type \"<f8\">)\n",
      "(u'CloudPressure', <HDF5 dataset \"CloudPressure\": shape (58634, 1), type \"<f8\">)\n",
      "(u'SZA', <HDF5 dataset \"SZA\": shape (58634, 1), type \"<f8\">)\n",
      "(u'VZA', <HDF5 dataset \"VZA\": shape (58634, 1), type \"<f8\">)\n",
      "(u'autocorrelation', <HDF5 dataset \"autocorrelation\": shape (58634,), type \"<f8\">)\n",
      "(u'chi2_red', <HDF5 dataset \"chi2_red\": shape (58634,), type \"<f8\">)\n",
      "(u'height', <HDF5 dataset \"height\": shape (58634, 1), type \"<f8\">)\n",
      "(u'lat', <HDF5 dataset \"lat\": shape (58634, 1), type \"<f8\">)\n",
      "(u'lon', <HDF5 dataset \"lon\": shape (58634, 1), type \"<f8\">)\n",
      "(u'param', <HDF5 dataset \"param\": shape (58634, 16), type \"<f8\">)\n",
      "(u'param_cov', <HDF5 dataset \"param_cov\": shape (58634, 16, 16), type \"<f8\">)\n",
      "(u'refl_err', <HDF5 dataset \"refl_err\": shape (58634, 120), type \"<f8\">)\n",
      "(u'res', <HDF5 dataset \"res\": shape (58634, 120), type \"<f8\">)\n",
      "(u'surf_albedo', <HDF5 dataset \"surf_albedo\": shape (58634, 1), type \"<f8\">)\n",
      "(u'wavelength', <HDF5 dataset \"wavelength\": shape (120,), type \"<f8\">)\n",
      "SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n",
      "(u'CloudFraction', <HDF5 dataset \"CloudFraction\": shape (53294, 1), type \"<f8\">)\n",
      "(u'CloudPressure', <HDF5 dataset \"CloudPressure\": shape (53294, 1), type \"<f8\">)\n",
      "(u'SZA', <HDF5 dataset \"SZA\": shape (53294, 1), type \"<f8\">)\n",
      "(u'VZA', <HDF5 dataset \"VZA\": shape (53294, 1), type \"<f8\">)\n",
      "(u'autocorrelation', <HDF5 dataset \"autocorrelation\": shape (53294,), type \"<f8\">)\n",
      "(u'chi2_red', <HDF5 dataset \"chi2_red\": shape (53294,), type \"<f8\">)\n",
      "(u'height', <HDF5 dataset \"height\": shape (53294, 1), type \"<f8\">)\n",
      "(u'lat', <HDF5 dataset \"lat\": shape (53294, 1), type \"<f8\">)\n",
      "(u'lon', <HDF5 dataset \"lon\": shape (53294, 1), type \"<f8\">)\n",
      "(u'param', <HDF5 dataset \"param\": shape (53294, 16), type \"<f8\">)\n",
      "(u'param_cov', <HDF5 dataset \"param_cov\": shape (53294, 16, 16), type \"<f8\">)\n",
      "(u'refl_err', <HDF5 dataset \"refl_err\": shape (53294, 120), type \"<f8\">)\n",
      "(u'res', <HDF5 dataset \"res\": shape (53294, 120), type \"<f8\">)\n",
      "(u'surf_albedo', <HDF5 dataset \"surf_albedo\": shape (53294, 1), type \"<f8\">)\n",
      "(u'wavelength', <HDF5 dataset \"wavelength\": shape (120,), type \"<f8\">)\n",
      "SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_allhpa_refset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(False, True, False)\n",
      "(u'CloudFraction', <HDF5 dataset \"CloudFraction\": shape (53294, 1), type \"<f8\">)\n",
      "(u'CloudPressure', <HDF5 dataset \"CloudPressure\": shape (53294, 1), type \"<f8\">)\n",
      "(u'SZA', <HDF5 dataset \"SZA\": shape (53294, 1), type \"<f8\">)\n",
      "(u'VZA', <HDF5 dataset \"VZA\": shape (53294, 1), type \"<f8\">)\n",
      "(u'autocorrelation', <HDF5 dataset \"autocorrelation\": shape (53294,), type \"<f8\">)\n",
      "(u'chi2_red', <HDF5 dataset \"chi2_red\": shape (53294,), type \"<f8\">)\n",
      "(u'height', <HDF5 dataset \"height\": shape (53294, 1), type \"<f8\">)\n",
      "(u'lat', <HDF5 dataset \"lat\": shape (53294, 1), type \"<f8\">)\n",
      "(u'lon', <HDF5 dataset \"lon\": shape (53294, 1), type \"<f8\">)\n",
      "(u'param', <HDF5 dataset \"param\": shape (53294, 16), type \"<f8\">)\n",
      "(u'param_cov', <HDF5 dataset \"param_cov\": shape (53294, 16, 16), type \"<f8\">)\n",
      "(u'refl_err', <HDF5 dataset \"refl_err\": shape (53294, 120), type \"<f8\">)\n",
      "(u'res', <HDF5 dataset \"res\": shape (53294, 120), type \"<f8\">)\n",
      "(u'surf_albedo', <HDF5 dataset \"surf_albedo\": shape (53294, 1), type \"<f8\">)\n",
      "(u'wavelength', <HDF5 dataset \"wavelength\": shape (120,), type \"<f8\">)\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print f\n",
    "    data        = hdf.File(f,'r') \n",
    "    group       = data['level2']\n",
    "    isFile   = isinstance(group,hdf.File)\n",
    "    isGroup  = isinstance(group,hdf.Group)\n",
    "    isDataset= isinstance(group,hdf.Dataset)\n",
    "    print (isFile,isGroup,isDataset)\n",
    "    list_items_in_group = group.items()\n",
    "    for i in list_items_in_group:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2011_allhpa_refset/2011/01/SIFTER2_M02_L2_2011_01_01')\n",
      "SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2011_allhpa_refset/2011/01/SIFTER2_M02_L2_2011_01_01\n",
      "(1, 'SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_erikrefset/2009/01/SIFTER2_M02_L2_2009_01_01\n",
      "(2, 'SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_allhpa_refset/2009/01/SIFTER2_M02_L2_2009_01_01')\n",
      "SIFTER2/Level_2_3_prev_runs/Level2_GOME2_2009_allhpa_refset/2009/01/SIFTER2_M02_L2_2009_01_01\n"
     ]
    }
   ],
   "source": [
    "columns                 = ['lat','lon','Fs','height','Autocorr','chi2']\n",
    "d                       = np.array(np.ones((58634,len(columns))))\n",
    "d2                      = np.array(np.ones((53294,len(columns))))\n",
    "\n",
    "dataF_GOME2_allhpa      = pd.DataFrame(data=d,columns=columns)\n",
    "dataF_GOME2_erik        = pd.DataFrame(data=d2,columns=columns)\n",
    "dataF_GOME2_allhpa_2009 = pd.DataFrame(data=d2,columns=columns)\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "    print (i,f)\n",
    "        \n",
    "    data      = hdf.File(f,'r') \n",
    "    lat       = np.array(data['level2/lat'])\n",
    "    lon       = np.array(data['level2/lon'])\n",
    "    autocorr  = np.array(data['level2/autocorrelation'])\n",
    "    refl_err  = np.array(data['level2/refl_err'])\n",
    "    residuals = np.array(data['level2/res'])\n",
    "    wav       = np.array(data['level2/wavelength'])\n",
    "    chi2      = np.array(data['level2/chi2_red'])\n",
    "    height    = np.array(data['level2/height'])\n",
    "    Fs        = np.array(data['level2/param'])\n",
    "    Fs        = np.array([item[0] for item in Fs])\n",
    "    cov       = np.array(data['level2/param_cov'])\n",
    "        \n",
    "    if i == 0:\n",
    "        print (f)\n",
    "        dataF_GOME2_allhpa['Autocorr']  = autocorr\n",
    "        dataF_GOME2_allhpa['Fs']        = Fs\n",
    "        dataF_GOME2_allhpa['height']    = height\n",
    "        dataF_GOME2_allhpa['chi2']      = chi2\n",
    "        dataF_GOME2_allhpa['lat']       = lat\n",
    "        dataF_GOME2_allhpa['lon']       = lon\n",
    "        resGOME2_allhpa                 = residuals \n",
    "        dataF_GOME2_allhpa.to_pickle('dataframes/df_GOME2_2011_allhpa')\n",
    "        \n",
    "    if i == 1:\n",
    "        print (f)\n",
    "        dataF_GOME2_erik['Autocorr']  = autocorr\n",
    "        dataF_GOME2_erik['Fs']        = Fs\n",
    "        dataF_GOME2_erik['height']    = height\n",
    "        dataF_GOME2_erik['chi2']      = chi2\n",
    "        dataF_GOME2_erik['lat']       = lat\n",
    "        dataF_GOME2_erik['lon']       = lon\n",
    "        resGOME2_erik                 = residuals \n",
    "        dataF_GOME2_erik.to_pickle('dataframes/df_GOME2_2009_erik')\n",
    "    \n",
    "    if i == 2:\n",
    "        print (f)\n",
    "        dataF_GOME2_allhpa_2009['Autocorr']  = autocorr\n",
    "        dataF_GOME2_allhpa_2009['Fs']        = Fs\n",
    "        dataF_GOME2_allhpa_2009['height']    = height\n",
    "        dataF_GOME2_allhpa_2009['chi2']      = chi2\n",
    "        dataF_GOME2_allhpa_2009['lat']       = lat\n",
    "        dataF_GOME2_allhpa_2009['lon']       = lon\n",
    "        resGOME2_allhpa_2009                 = residuals \n",
    "        dataF_GOME2_allhpa_2009.to_pickle('dataframes/df_GOME2_2009_allhpa')\n",
    "           \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
